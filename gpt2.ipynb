{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a3332ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('story.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17135edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {}\n",
    "index2char = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13bc8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index['#'] = 0\n",
    "index2char[0] = '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e0d843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = set(text)\n",
    "for i,c in enumerate(all_chars):\n",
    "    char2index[c] = i+1\n",
    "    index2char[i+1] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16142145",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char2index)\n",
    "hidden_dim = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea94095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b42d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(embed_dim,embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim,embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim,vocab_size),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,seq):\n",
    "        # seq batch seq_len\n",
    "        embedding = self.embedding(seq) # batch seq_len embedding_dim\n",
    "        last = embedding[:,-1,:] # batch 1 embedding_dim\n",
    "        last = last.squeeze(1) # batch embedding_dim\n",
    "        logits = self.seq(last) # batch vocab_size\n",
    "        probs = self.sigmoid(logits) # batch vocab_size\n",
    "        return probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a47f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25a5a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48e8ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = []\n",
    "all_y = []\n",
    "x = [0]*context_len\n",
    "for c in text:\n",
    "    index = char2index[c]\n",
    "    y = index\n",
    "    all_x.append(x)\n",
    "    all_y.append(y)\n",
    "    x = x[1:]+[index]\n",
    "all_x = torch.tensor(all_x)\n",
    "all_y = torch.tensor(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fdffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2582a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(vocab_size,hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c630d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a283c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32cb3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = optim.Adam(mlp.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb2ebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af07832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b06f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cb70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae811463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7657b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(n):\n",
    "    idxs = torch.randint(0,all_x.shape[0],(n,))\n",
    "    xx = all_x[idxs]\n",
    "    yy = all_y[idxs]\n",
    "    return xx,yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c23e978b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 60,  81,  98,   3,  71,  21,  56,  95,   7, 116,  94, 102,  17,  69,\n",
       "           29,  85,  45,  11, 119,   7,  23, 118,  17,  69,  82,  14, 118,  56,\n",
       "           50,  83],\n",
       "         [ 56,  10, 100,  81, 116,  94, 101,  55, 106,  20, 102,  51,  60,  81,\n",
       "           98,   3,  71,  21,  56,  95,   7, 116,  94, 102,  17,  69,  29,  85,\n",
       "           45,  11],\n",
       "         [  9,  75,  95,   5,  46, 131,  70, 112, 122,  81,  79,  82,  59,  74,\n",
       "           36, 102,  97,  33,  20,  81,  93,  12,  84, 121, 105,  25,  11, 117,\n",
       "           45,  19],\n",
       "         [  7, 116,  94,  51,  60, 108,  90,  59,  81,   6,   1,  64, 124,  23,\n",
       "          113, 130,  40, 102,  67,  66,  81,  43, 114,  17,  49,  77, 103,  73,\n",
       "           81,  97],\n",
       "         [ 54,  58,  22,  11, 109, 116,  94,  93,  12,  84, 121, 102, 110,  72,\n",
       "           45,  41,  27,  30,  14, 118,  48,  63,  96,  42,  81,  57, 104,  75,\n",
       "           39,  24],\n",
       "         [ 62,  81,  35,   8,  84, 121, 102, 130,  40,  67,  66,   7, 116,  94,\n",
       "           51,  60, 108,  90,  59,  81,   6,   1,  64, 124,  23, 113, 130,  40,\n",
       "          102,  67],\n",
       "         [ 33,  20,  81,  93,  12,  84, 121, 105,  25,  11, 117,  45,  19, 125,\n",
       "          102,  48,  63,  95,  52,  56,  31,  86,  65,  34,  23,  53,  87,   7,\n",
       "          120, 119],\n",
       "         [ 73,  81,  97,  33,  57,  71,  44,  47,   4, 122,  14, 118,  80,  91,\n",
       "          115,  45,  26,   4, 122,  80,  91, 115,  96,  42,  81,  42,  37, 102,\n",
       "           31, 126],\n",
       "         [123,  38, 107, 101,  71,  80, 111, 102,  81,  16,  25,   2,  61,  71,\n",
       "           21,  56,  10, 100,  81, 116,  94, 101,  55, 106,  20, 102,  51,  60,\n",
       "           81,  98],\n",
       "         [ 66,  81,  43, 114,  17,  49,  77, 103,  73,  81,  97,  33,  57,  71,\n",
       "           44,  47,   4, 122,  14, 118,  80,  91, 115,  45,  26,   4, 122,  80,\n",
       "           91, 115]]),\n",
       " tensor([129, 119, 125,  33,  84,  66,  62,   9,   3,  96]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d732dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fdea1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9410, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9361, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9198, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    xx,yy = get_data(batch_n)\n",
    "    probs = mlp(xx)\n",
    "    loss =  criterion(probs,yy)\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "    op.zero_grad()\n",
    "    loss.backward()\n",
    "    op.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6c05139",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '你'\n",
    "index = char2index[start]\n",
    "xx = [index]\n",
    "for _ in range(100):\n",
    "    input_x = torch.tensor(xx)\n",
    "    probs = mlp(input_x.view(1,-1)).view(-1) # vocabsize\n",
    "    choice = torch.multinomial(probs,1)\n",
    "    xx = xx + [choice.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98bde301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你想的事半的知识在的第一篇关的的文的路的必要的阶的路线的角度的阶的阶的，就踏的阶的知的，就很容易形的必要知识的角的知的的时的，详细写的的角的那的那么的必的阶的那么的角度，因的的时的时候有你想象的时的第的\n"
     ]
    }
   ],
   "source": [
    "print(''.join([index2char[index] for index in xx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a935a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d62da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5df77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_ktm",
   "language": "python",
   "name": "edu_ktm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_path = '/Users/liuchu/linear_algebra_strang/translate/中英翻译数据集/train/news-commentary-v13.zh-en.en'\n",
    "zh_path = '/Users/liuchu/linear_algebra_strang/translate/中英翻译数据集/train/news-commentary-v13.zh-en.zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_en_sentences():\n",
    "    arr = []\n",
    "    with open(en_path,'r') as f:\n",
    "        count = 0\n",
    "        for line in f.readlines():\n",
    "            arr.append(line.strip())\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zh_sentences():\n",
    "    arr = []\n",
    "    with open(zh_path,'r') as f:\n",
    "        count = 0\n",
    "        for line in f.readlines():\n",
    "            arr.append(line.strip().replace(' ',''))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = get_en_sentences()\n",
    "zh_sentences = get_zh_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = en_sentences\n",
    "target_sentences = zh_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS_token是起始符号的标记\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:  # EOS_token是结束符号的标记\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(vocab, sentence):\n",
    "    indices = [vocab[char] for char in sentence if char in vocab]  # Ensure char is in vocab\n",
    "    indices.append(vocab['<eos>'])  # Append EOS token\n",
    "    return torch.tensor(indices, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def translate_sentence(sentence, encoder, decoder, input_vocab, output_vocab):\n",
    "    input_tensor = tensorFromSentence(input_vocab, sentence)\n",
    "    translated_sentence = translate(encoder, decoder, input_tensor, input_vocab, output_vocab)\n",
    "    return translated_sentence\n",
    "\n",
    "def translate(encoder, decoder, input_tensor, input_vocab, output_vocab, max_length=100):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        # Forward pass through encoder\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "        # Decoder's first input is SOS token\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_word = output_vocab[topi.item()]\n",
    "                decoded_words.append(decoded_word)\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设语料数据如下，这里我们使用了非常简单的例子\n",
    "chinese_sentences = zh_sentences[:20]\n",
    "english_sentences = en_sentences[:20]\n",
    "\n",
    "# 为了简化问题，我们不使用词嵌入，而是直接根据字母或汉字进行索引\n",
    "def create_dict(sentences):\n",
    "    vocab = set(''.join(sentences))\n",
    "    char_to_index = {char: i+1 for i, char in enumerate(vocab)}  # +1因为我们留出0作为padding\n",
    "    char_to_index['<pad>'] = 0\n",
    "    index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "    return char_to_index, index_to_char\n",
    "\n",
    "chinese_vocab, chinese_index_vocab = create_dict(chinese_sentences)\n",
    "chinese_vocab['<sos>'] = max(chinese_vocab.values()) + 1\n",
    "chinese_index_vocab[chinese_vocab['<sos>']] = '<sos>'\n",
    "\n",
    "english_vocab, english_index_vocab = create_dict(english_sentences)\n",
    "\n",
    "# 将句子转换为索引\n",
    "def sentence_to_indices(sentence, vocab):\n",
    "    return [vocab[char] for char in sentence]\n",
    "\n",
    "chinese_data = [sentence_to_indices(sentence, chinese_vocab) for sentence in chinese_sentences]\n",
    "english_data = [sentence_to_indices(sentence, english_vocab) for sentence in english_sentences]\n",
    "\n",
    "# 增加开始和结束标记\n",
    "\n",
    "SOS_token = english_vocab['<sos>'] = max(english_vocab.values()) + 1\n",
    "EOS_token = english_vocab['<eos>'] = max(english_vocab.values()) + 1\n",
    "english_index_vocab[SOS_token] = '<sos>'\n",
    "english_index_vocab[EOS_token] = '<eos>'\n",
    "english_data = [[SOS_token] + sentence + [EOS_token] for sentence in english_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 61)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_index_vocab),len(english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chinese_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为torch张量\n",
    "def to_tensor(data):\n",
    "    return torch.tensor(data, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "chinese_tensors = [to_tensor(data) for data in chinese_data]\n",
    "english_tensors = [to_tensor(data) for data in english_data]\n",
    "\n",
    "# 训练参数设置\n",
    "num_epochs = 100\n",
    "\n",
    "encoder = Encoder(len(chinese_vocab), 256).to(device)\n",
    "decoder = Decoder(256, len(english_vocab)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.2947\n",
      "Epoch 20, Loss: 1.2528\n",
      "Epoch 30, Loss: 1.2216\n",
      "Epoch 40, Loss: 1.1722\n",
      "Epoch 50, Loss: 1.1268\n",
      "Epoch 60, Loss: 1.1587\n",
      "Epoch 70, Loss: 1.1772\n",
      "Epoch 80, Loss: 1.0730\n",
      "Epoch 90, Loss: 1.0060\n",
      "Epoch 100, Loss: 1.0074\n",
      "Epoch 110, Loss: 1.0013\n",
      "Epoch 120, Loss: 0.9668\n",
      "Epoch 130, Loss: 0.9527\n",
      "Epoch 140, Loss: 0.8626\n",
      "Epoch 150, Loss: 0.8662\n",
      "Epoch 160, Loss: 0.8606\n",
      "Epoch 170, Loss: 0.8620\n",
      "Epoch 180, Loss: 0.8199\n",
      "Epoch 190, Loss: 0.7778\n",
      "Epoch 200, Loss: 2.5917\n",
      "Epoch 210, Loss: 2.4215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-85ee2ab1134e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mch_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchinese_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menglish_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-ed0640575a3f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练循环\n",
    "for epoch in range(num_epochs+200):\n",
    "    total_loss = 0\n",
    "    for ch_tensor, en_tensor in zip(chinese_tensors, english_tensors):\n",
    "        loss = train(ch_tensor, en_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        total_loss += loss\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(chinese_sentences):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?',\n",
       " '巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正在发生的情况。',\n",
       " '一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为这两段时期意味着典型的周期性衰退。',\n",
       " '如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政府的表现仍然似乎把视目前的情况为是典型的而看见的衰退。',\n",
       " '目前的趋势是，要么是过度的克制（欧洲），要么是努力的扩展（美国）。',\n",
       " '欧洲在避免债务和捍卫欧元的名义下正变得谨慎，而美国已经在许多方面行动起来，以利用这一理想的时机来实行急需的结构性改革。',\n",
       " '然而，作为地域战略学家，无论是从政治意义还是从经济意义上，让我自然想到的年份是1989年。',\n",
       " '当然，雷曼兄弟公司的倒闭和柏林墙的倒塌没有任何关系。',\n",
       " '事实上，从表面上看，两者似乎是完全是相反的：一个是象征着压抑和人为分裂的柏林墙的倒塌，而另一个是看似坚不可摧的并令人安心的金融资本主义机构的倒塌。',\n",
       " '然而，和1989年一样，2008-2009年很可能也能被视为一个划时代的改变，其带来的发人深省的后果将在几十年后仍能让我们感受得到。']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929 or 1989?',\n",
       " 'PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.',\n",
       " 'At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.',\n",
       " 'Today, the mood is much grimmer, with references to 1929 and 1931 beginning to abound, even if some governments continue to behave as if the crisis was more classical than exceptional.',\n",
       " 'The tendency is either excessive restraint (Europe) or a diffusion of the effort (the United States).',\n",
       " 'Europe is being cautious in the name of avoiding debt and defending the euro, whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms.',\n",
       " 'For geo-strategists, however, the year that naturally comes to mind, in both politics and economics, is 1989.',\n",
       " 'Of course, the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall.',\n",
       " 'Indeed, on the surface it seems to be its perfect antithesis: the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism.',\n",
       " 'Yet 2008-2009, like 1989, may very well correspond to an epochal change, whose unfolding consequences will be felt for decades.']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> 1 9 2 9   o r   1 9 8 9 ? <EOS>\n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(sentence):\n",
    "    indices = sentence_to_indices(sentence, chinese_vocab)\n",
    "    tensor = to_tensor(indices)\n",
    "    translation = translate(encoder, decoder, tensor, chinese_index_vocab, english_index_vocab)\n",
    "    return translation\n",
    "\n",
    "# 翻译示例\n",
    "print(translate_sentence('1999年还是1999年?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch size 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)  # Set batch_first to True\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)  # input: (batch_size, seq_len)\n",
    "        output, hidden = self.gru(embedded, hidden)  # No need to permute\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)  # Set batch_first to True\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)  # input: (batch_size,seq)\n",
    "#         output = output.unsqueeze(1)  # Change to (batch_size, 1, hidden_size)\n",
    "        output = nn.functional.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)  # No need to permute\n",
    "        output = self.softmax(self.out(output.squeeze(1)))  # Squeeze to remove the sequence length dimension\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10):\n",
    "    batch_size = input_tensor.size(0)\n",
    "    input_length = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encode the input sequence batch\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    # Prepare the initial decoder input (start with SOS tokens for each sequence in the batch)\n",
    "    decoder_input = torch.tensor([[SOS_token] * batch_size], device=device).transpose(0, 1)  # Shape: (batch_size, 1)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Assuming teacher forcing is not used here. If desired, it can be included with a certain probability.\n",
    "    for di in range(target_length):\n",
    "#         print(decoder_input.shape)\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.detach()  # Prepare next input\n",
    "#         print(decoder_output.shape,target_tensor[:, di].shape,decoder_input.shape)\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[:, di])\n",
    "\n",
    "        # Optionally, stop when all sequences in the batch reach EOS token\n",
    "        if (decoder_input == EOS_token).all():\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / (target_length * batch_size)  # Normalize loss by total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 10  # Example vocabulary size for encoder\n",
    "output_size = 10  # Example vocabulary size for decoder\n",
    "hidden_size = 256\n",
    "batch_size = 5\n",
    "max_length = 7  # Maximum length of input and output sequences\n",
    "epochs = 10\n",
    "\n",
    "# Special tokens\n",
    "SOS_token = 0  # Start-of-sequence token\n",
    "EOS_token = 1  # End-of-sequence token\n",
    "\n",
    "# Instantiate models\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size, output_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.01)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_batch(batch_size, max_length, vocabulary_size):\n",
    "    \"\"\" Generate a random batch of sequences for training. \"\"\"\n",
    "    # Random sequences of random lengths\n",
    "    sequences = torch.randint(2, vocabulary_size, (batch_size, max_length)).to(device)\n",
    "    return sequences\n",
    "\n",
    "# Example of generating a batch\n",
    "input_tensor = generate_fake_batch(batch_size, max_length, input_size)\n",
    "target_tensor = generate_fake_batch(batch_size, max_length, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 4, 9, 8, 2, 7],\n",
       "        [6, 6, 7, 6, 8, 2, 5],\n",
       "        [9, 5, 6, 7, 3, 4, 4],\n",
       "        [4, 5, 5, 5, 7, 7, 5],\n",
       "        [3, 5, 6, 2, 5, 2, 2]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4680\n",
      "Epoch 2, Loss: 0.5614\n",
      "Epoch 3, Loss: 0.4901\n",
      "Epoch 4, Loss: 0.5791\n",
      "Epoch 5, Loss: 0.5343\n",
      "Epoch 6, Loss: 0.4939\n",
      "Epoch 7, Loss: 0.4654\n",
      "Epoch 8, Loss: 0.4840\n",
      "Epoch 9, Loss: 0.4593\n",
      "Epoch 10, Loss: 0.4287\n",
      "Average Loss: 0.4964\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(encoder, decoder, input_tensor, target_tensor):\n",
    "    loss_total = 0  # Track loss\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Generate new data for each epoch\n",
    "        input_tensor = generate_fake_batch(batch_size, max_length, input_size)\n",
    "        target_tensor = generate_fake_batch(batch_size, max_length, output_size)\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\n",
    "        loss_total += loss\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n",
    "\n",
    "    print(f'Average Loss: {loss_total / epochs:.4f}')\n",
    "\n",
    "# Call the training function\n",
    "train_epoch(encoder, decoder, input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

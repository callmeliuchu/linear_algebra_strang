{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4435158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.embedding = nn.Embedding(output_size, input_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x [batch_size, seq_len]\n",
    "        x = self.embedding(x) # batch seq_len \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "\n",
    "        # Only take the output from the last time step\n",
    "#         out = out[:, -1, :]\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bbce550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bcb8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy=get_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8d1defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2632,  790, 1424,  232, 1420,  790, 1075, 2783, 1383, 2356,  242, 2260,\n",
       "         1902, 2111, 1130, 2674, 2603, 2603, 2519, 2638, 1420, 1465,  273,  468,\n",
       "         2632, 1130, 1099, 2480,  329, 2991],\n",
       "        [1424, 1420, 1216,  706,  587, 1954, 1199, 1420,  440, 1875, 1902, 1210,\n",
       "         1210, 1047, 2795,  440,  389, 1420, 1216,  706,  587, 1007, 2827, 1420,\n",
       "         2790, 1143, 2775,  526, 1420, 1045],\n",
       "        [ 816,  217, 2114, 1259,  975, 1424, 1130, 2592, 1383, 1420, 1167,  389,\n",
       "         2864, 2034, 1420, 2500, 2836,  406, 2668,  706, 2988,  222, 2478, 2914,\n",
       "         1130, 2674, 2603, 2603, 1250, 1430],\n",
       "        [ 216, 1420,   89,  200, 1420, 1902,  507, 1423, 2593, 1915, 1424, 1697,\n",
       "         1369, 1473,   76, 2775, 1424, 1665,  587, 2718,  596, 1891,  570,  688,\n",
       "         2332,  706, 2914, 2653, 1966, 2718],\n",
       "        [1075, 2250, 1420, 1574, 1188, 1182,  206, 2928, 2683, 2436, 1420, 1188,\n",
       "         1182,  816, 2025, 2088, 1420, 1683,  184,  273, 2025, 1188, 1182, 2802,\n",
       "         2145, 1424, 2881,  774, 1771, 1212],\n",
       "        [2632,  706,  909, 1075, 2425, 1420,  962, 1108, 1350,  273, 1117,  264,\n",
       "         2632, 1420, 1075, 1033, 2194, 1902,  706,  538,  322, 2505, 1930, 1930,\n",
       "         2834, 2896, 2834, 2895, 2194, 2922],\n",
       "        [2119,  524, 1889, 1604, 2250,  264, 2632, 1455, 1732, 2463, 2305,  962,\n",
       "         1751,  636, 1424, 2061, 1412, 1659, 1443, 1130,  587, 1167, 2463, 2317,\n",
       "         2957, 2896,  107, 1130, 2603, 2603],\n",
       "        [ 767,  688, 2332,  706, 1196, 2123,  499, 2305, 2636, 1455, 1505, 1424,\n",
       "         1196, 2674, 1130, 1455, 1505, 1424, 1196, 1574,  850,  499, 1906,  109,\n",
       "          103, 1130, 1695,  556, 2691, 1335],\n",
       "        [2519, 2986, 2044, 1420, 1188,  705, 2284,  790, 1509,  214, 2632,  444,\n",
       "         1840,  389, 1424,  917,  620, 1420,  790, 1182, 2790, 1143, 2988, 1079,\n",
       "         1424,  917,  620, 1130, 2603, 2603],\n",
       "        [  19, 1383, 1420, 1421,  741, 2238, 2375, 2795, 1713, 1249, 2394, 1424,\n",
       "          376,  526, 1420, 1431, 2790,  229,  456, 1385,  457,   21,   21,  793,\n",
       "          793, 1424, 2923,  416, 1420,  229]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f62de6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c13176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa352ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = SimpleRNN(embedding_size,50,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "681bf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rnn(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b69fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30, 3005])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2069df7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a1375b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07fff7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.0161, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(probs.view(-1,vocab_size),yy.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97faf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e359977",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = optim.Adam(rnn.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9dae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.2162, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2286, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2348, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2371, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2271, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2195, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2111, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2147, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2100, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2046, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2101, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2141, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1964, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1876, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2134, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    xx,yy = get_data(batch_n)\n",
    "    probs = rnn(xx)\n",
    "    loss =  criterion(probs.view(-1,vocab_size),yy.view(-1))\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "    op.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1.0)\n",
    "    op.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1d27153",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '你们是谁？'\n",
    "\n",
    "xx = [char2index[x] for x in start]\n",
    "for _ in range(100):\n",
    "    input_x = torch.tensor(xx)\n",
    "    probs = rnn(input_x.view(1,-1))[:,-1,:].view(-1) # vocabsize\n",
    "    choice = torch.multinomial(probs,1)\n",
    "    xx = xx + [choice.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b09b4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你们是谁？成实跑也应树一串苍深突作市尾”面长…花西般寓金假后中本运爱香！月往水科门脸起小路妈给为王里心本猫也头朝好完可不适饭吧去国越出小草开一我同老多大个朝时爱用看传我只已好想吃“人像。什。刚翔成机算们向呢心也\n"
     ]
    }
   ],
   "source": [
    "print(''.join([index2char[index] for index in xx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633264a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_ktm",
   "language": "python",
   "name": "edu_ktm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
